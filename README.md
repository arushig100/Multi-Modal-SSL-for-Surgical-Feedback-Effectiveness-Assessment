General code for running self-supervised pretraining/fine-tuning of VideoMAE is in pretrain_videomae.py

The pipeline for running supervised fine-tuning of VideoMAE, supervised training of the multi-modal model, and supervised training of text involves the following:

1. Run save_data.py to save video data that is preprocessed for VideoMAE, SBERT text features, and labels (i.e., trainee behavior change labels)
2. To run supervised fine-tuning of VideoMAE: Run finetune_videomae.py that uses the dataset generated from the previous step to then fine-tune VideoMAE for a prediction task. This will generate a directory that contains VideoMAE features (for the train and test sets), SBERT features (for the train and test sets), and fine-tuned VideoMAE model across all epochs of training.
3. To run supervised training of multi-modal model: Run finetune_multimodal.py that uses a directory generated by Step 2 to perform multi-modal training of the VideoMAE features and SBERT features at a specific epoch for the prediction task. 
4. To run supervised training of text: Run train_text.py that uses a directory generated by Step 2 to perform training of the SBERT features for the prediction task.


